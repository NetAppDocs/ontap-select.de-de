---
sidebar: sidebar 
permalink: concept_stor_vsan_external.html 
keywords: ontap select, vsan and external array configurations, vnas architecture 
summary: 'Virtual NAS (vNAS)-Bereitstellungen unterstützen ONTAP Select Cluster auf vSAN, einige HCI-Produkte, NetApp HCI Technologie und externe Array-Typen von Datenspeichern. Die zugrunde liegende Infrastruktur dieser Konfigurationen sorgt für Datenspeicher-Resilienz.' 
---
= ONTAP Select vSAN und externe Array-Konfigurationen
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Virtual NAS (vNAS)-Bereitstellungen unterstützen ONTAP Select Cluster auf Virtual SAN (vSAN), einige HCI-Produkte und externe Array-Typen von Datenspeichern. Die zugrunde liegende Infrastruktur dieser Konfigurationen sorgt für Datenspeicher-Resilienz.

Die Mindestanforderung besteht darin, dass der von Ihnen verwendete Hypervisor (VMware ESXi oder KVM auf einem unterstützten Linux-Host) die zugrunde liegende Konfiguration unterstützt.  Wenn es sich bei dem Hypervisor um ESXi handelt, sollte er in den entsprechenden VMware-HCLs aufgeführt sein.



== VNAS Architektur

Die vNAS-Nomenklatur wird für alle Setups verwendet, die kein DAS nutzen. Für ONTAP Select Multi-Node-Cluster umfasst dies Architekturen, bei denen die beiden ONTAP Select Nodes im selben HA-Paar einen gemeinsamen Datenspeicher (einschließlich vSAN-Datenspeicher) nutzen. Die Nodes können auch auf separaten Datenspeichern desselben gemeinsam genutzten externen Arrays installiert werden. Dies ermöglicht Speichereffizienzen auf Array-Seite, um den Gesamtbedarf des gesamten ONTAP Select HA-Paars zu reduzieren. Die Architektur von ONTAP Select vNAS-Lösungen ist der von ONTAP Select auf DAS mit lokalem RAID-Controller sehr ähnlich. Das bedeutet, dass jeder ONTAP Select Node weiterhin eine Kopie der Daten seines HA-Partners hat. ONTAP Speichereffizienzrichtlinien sind Node-bezogen. Daher sind Speichereffizienzen auf Array-Seite vorzuziehen, da sie potenziell auf Datensätze beider ONTAP Select Nodes angewendet werden können.

Möglicherweise verwendet jeder ONTAP Select Node in einem HA-Paar zudem ein separates externes Array. Dies ist eine gängige Wahl bei der Verwendung von ONTAP Select MetroCluster-SDS mit externem Speicher.

Beim Einsatz separater externer Arrays für jeden ONTAP Select Node ist es sehr wichtig, dass die beiden Arrays ähnliche Performance-Merkmale mit der ONTAP Select VM aufweisen.



=== VNAS Architekturen gegenüber lokalen das mit Hardware-RAID-Controllern

Die vNAS Architektur ähnelt logisch der Architektur eines Servers mit das und einem RAID-Controller. In beiden Fällen verbraucht ONTAP Select den Datenspeicher-Speicherplatz. Dieser Datenspeicherplatz wird auf VMDKs aufgeteilt. Diese VMDKs stellen die herkömmlichen ONTAP-Datenaggregate dar. ONTAP Deploy stellt sicher, dass die VMDKs richtig dimensioniert sind und der korrekten Plex (im Fall von HA-Paaren) während der Cluster-Erstellung und beim Storage-Hinzufügen zugewiesen sind.

Es gibt zwei große Unterschiede zwischen vNAS und das mit einem RAID-Controller. Der unmittelbare Unterschied ist, dass vNAS keinen RAID-Controller benötigt. VNAS geht davon aus, dass das zugrunde liegende externe Array die Datenpersistenz und Ausfallsicherheit bietet, die ein das mit einer RAID-Controller-Einrichtung bieten würde. Der zweite und feinstoffere Unterschied hat mit der NVRAM-Performance zu tun.



== VNAS NVRAM

Der ONTAP Select NVRAM ist ein VMDK. Dies bedeutet, dass ONTAP Select einen byteadressierbaren Speicherplatz (herkömmliches NVRAM) auf einem blockadressierbaren Gerät (VMDK) emuliert. Die Leistung des NVRAM ist jedoch entscheidend für die Gesamtleistung des ONTAP Select Knotens.

Bei DAS-Setups mit einem Hardware-RAID-Controller fungiert der Cache des Hardware-RAID-Controllers als NVRAM Cache, da alle Schreibvorgänge in die NVRAM VMDK zuerst im Cache des RAID-Controllers gehostet werden.

Bei VNAS-Architekturen konfiguriert ONTAP Deploy die ONTAP Select-Nodes automatisch mit einem Boot-Argument namens Single Instance Data Logging (SIDL). Wenn dieses Boot-Argument vorhanden ist, wird der NVRAM durch ONTAP Select umgangen und die Datenlast direkt auf das Datenaggregat geschrieben. Der NVRAM wird nur verwendet, um die Adresse der vom SCHREIBVORGANG geänderten Blöcke aufzunehmen. Der Vorteil dieser Funktion besteht darin, dass doppelte Schreibvorgänge vermieden werden: Ein Schreibvorgang in NVRAM und ein zweiter Schreibvorgang, wenn der NVRAM entfernt wird. Diese Funktion ist nur für vNAS aktiviert, da lokale Schreibvorgänge in den RAID-Controller-Cache eine unwesentlich zusätzliche Latenz haben.

DIE SIDL-Funktion ist nicht mit allen ONTAP Select-Storage-Effizienzfunktionen kompatibel. Die SIDL-Funktion kann auf Aggregatebene mit folgendem Befehl deaktiviert werden:

[listing]
----
storage aggregate modify -aggregate aggr-name -single-instance-data-logging off
----

NOTE: Die Schreibleistung wird beeinträchtigt, wenn die SIDL-Funktion deaktiviert ist. Es ist möglich, die SIDL-Funktion wieder zu aktivieren, nachdem alle Speichereffizienzrichtlinien auf allen Volumes in diesem Aggregat deaktiviert wurden:

[listing]
----
volume efficiency stop -all true -vserver * -volume * (all volumes in the affected aggregate)
----


== Collocate ONTAP Select-Knoten bei Verwendung von vNAS auf ESXi

ONTAP Select bietet Unterstützung für Multi-Node ONTAP Select Cluster auf gemeinsam genutztem Speicher. ONTAP Deploy ermöglicht die Konfiguration mehrerer ONTAP Select Nodes auf demselben ESXi-Host, solange diese Nodes nicht Teil desselben Clusters sind.


NOTE: Diese Konfiguration ist nur für VNAS-Umgebungen (gemeinsam genutzte Datenspeicher) gültig. Mehrere ONTAP Select Instanzen pro Host werden bei Verwendung von DAS-Speicher nicht unterstützt, da diese Instanzen um denselben Hardware RAID-Controller konkurrieren.

ONTAP Deploy stellt sicher, dass bei der ersten Bereitstellung des Multi-Node-VNAS-Clusters nicht mehrere ONTAP Select Instanzen desselben Clusters auf demselben Host platziert werden. Die folgende Abbildung zeigt ein Beispiel für die korrekte Bereitstellung von zwei Vier-Node-Clustern, die sich auf zwei Hosts überschneiden.

*Erstmalige Bereitstellung von Multi-Node-VNAS-Clustern*

image:ST_14.jpg["Erste Bereitstellung von Multi-Node-VNAS-Clustern"]

Nach der Implementierung können die ONTAP Select-Nodes zwischen den Hosts migriert werden. Dies könnte zu nicht optimalen und nicht unterstützten Konfigurationen führen, bei denen zwei oder mehr ONTAP Select Nodes aus demselben Cluster sich den gleichen zugrunde liegenden Host teilen. NetApp empfiehlt die manuelle Erstellung von Regeln zur Affinität von VMs, damit VMware automatisch die physische Trennung zwischen den Nodes desselben Clusters trennt. Nicht nur die Nodes aus dem gleichen HA-Paar.


NOTE: Anti-Affinitätsregeln erfordern, dass DRS auf dem ESXi-Cluster aktiviert ist.

Im folgenden Beispiel wird gezeigt, wie eine Anti-Affinität-Regel für ONTAP Select VMs erstellt wird. Wenn der ONTAP Select Cluster mehr als ein HA-Paar enthält, müssen alle Nodes im Cluster in dieser Regel enthalten sein.

image:ST_15.jpg["VM/Host-Regeln"]

image:ST_16.jpg["Bearbeiten Sie die VM/Host-Regel"]

Zwei oder mehr ONTAP Select Nodes aus demselben ONTAP Select Cluster könnten aus einem der folgenden Gründe auf demselben ESXi-Host gefunden werden:

* DRS ist nicht vorhanden, weil Einschränkungen zu VMware vSphere Lizenzen bestehen oder wenn DRS nicht aktiviert ist.
* Die Anti-Affinitätsregel DRS wird umgangen, weil ein VMware HA-Vorgang oder eine durch den Administrator initiierte VM-Migration Vorrang hat.



NOTE: ONTAP Deploy überwacht die ONTAP Select VM-Standorte nicht proaktiv. Eine Clusteraktualisierung spiegelt diese nicht unterstützte Konfiguration jedoch in den ONTAP Deploy-Protokollen wider:

image:ST_17.PNG["ONTAP Deploy (Protokolle)"]
